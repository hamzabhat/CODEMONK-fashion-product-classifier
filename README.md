#  Fashion Product Classifier

A full-stack Machine Learning web application that predicts multiple attributes of fashion products from images using deep learning. This project was developed as part of a coding assignment for Codemonkâ€™s Machine Learning Internship.

---

## ğŸš€ Project Overview

Given an input image of a fashion product, this system predicts the following four attributes:

-  **Color**
-  **Product Type**
-  **Season of Use**
-  **Target Gender**

It uses multi-task deep learning to handle all four tasks in a single model and provides visual heatmaps for interpretability.

---
## ğŸš§ Pending Improvements

While the core pipeline is completeâ€”from preprocessing to prediction and visualizationâ€”several improvements are planned to enhance functionality, performance, and user experience:

- **ğŸ§  Additional Architectures:**
    - [ ] Integrate Vision Transformer (ViT) with 4-head classification.
  - [ ] Experiment with Mixture-of-Experts (MoE) heads for advanced ensembling.

- **ğŸ“Š Evaluation & Metrics:**
  - [ ] Add confusion matrices and classification reports per task.
- **ğŸ”§ Backend Enhancements:**
  - [ ] Add batch image support for predictions.
- **ğŸ’¡ Explainability:**
  - [ ] Improve Grad-CAM precision by using hooks on intermediate layers.
---

## ğŸ“š Table of Contents

- [Project Overview](#project-overview)
- [Project Structure](#project-structure)
- [How to Run This Project](#ï¸how-to-run-this-project)
- [Example Output](#example-output)
- [Pending Improvements](#pending-improvements)
- [Model Checkpoints](#model-checkpoints)
- [Author](#author)


## ğŸ§± Project Architecture

### Multi-Head Learning Model 

- **Backbone**: `EfficientNetV2-S` (pretrained on ImageNet)
- **Shared Encoder**: Extracts rich image features
- **Four Classification Heads**:
  - Color
  - Product Type
  - Season
  - Gender
- **Regularization**: Dropout applied to each head
- **Loss**: Independent `CrossEntropyLoss` for each task
- **Training Framework**: PyTorch

> ğŸ† This model design is efficient, generalizes well, and leverages shared representations to boost performance across tasks.

---
## Frontend

- **Framework**: [Streamlit](https://streamlit.io)
- **Features**:
  - Upload fashion product image
  - Displays predicted color, type, season, and gender
  - Shows visual heatmap of model attention

---

## Backend

- **Framework**: [FastAPI](https://fastapi.tiangolo.com/)
- **APIs**:
  - `POST /predict`: Takes an image, returns predictions + heatmap path
- **Model Inference**:
  - Loads trained EfficientNet multi-task model
  - Decodes predicted labels using saved `label_encoders.json`

---
## Explainability

- **Grad-CAM** heatmaps are generated for each input image using the shared EfficientNet backbone.
- The heatmaps highlight which regions of the image were most influential in the predictions.

---



## Project Structure
```sh
fashion-product-classifier/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI app entrypoint
â”‚ â”œâ”€â”€ routes/ # API endpoints
â”‚ â”œâ”€â”€ services/ # Prediction logic, heatmap gen
â”‚ â”œâ”€â”€ utils/ # Preprocessing helpers
â”‚ â”œâ”€â”€ models/ # Model architecture + checkpoints + encodings 
â”‚ â”‚ â””â”€â”€ effi_net_backbone/
â”‚ â”‚ â”œâ”€â”€ model_efficientnet.pth
â”‚ â”‚ â””â”€â”€ label_encoders.json
â”‚ â””â”€â”€ static/ # Heatmaps served here
â”‚ â””â”€â”€ heatmaps/
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ app.py # Streamlit frontend UI
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ fashion-product-images-dataset/
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ cleaned_styles.csv
â”‚ â””â”€â”€ distribution_plots/
â”‚
â”œâ”€â”€ data_preprocessing/
â”‚ â”œâ”€â”€ clean_data.py # CSV cleaning
â”‚ â””â”€â”€ class_distribution.py # Plots label distributions
â”‚
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ efficientnet_training.py # EfficientNet training script
â”‚ â””â”€â”€ vit_training.py # (NOT IMPLEMENTED YET) ViT training script
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ› ï¸ How to Run This Project

###  Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

> Ensure you have:
> - Python 3.8+
> - PyTorch with GPU support (optional but recommended)

---

###  Step 2: Preprocess the Dataset

```bash
python data_preprocessing/clean_data.py
python data_preprocessing/class_distribution.py
```

---

###  Step 3: Train the Model
***Option 1*** â€” Train from scratch:
```bash
python training/efficientnet_training.py
```
This will save:
- Model weights to: `backend/models/effi_net_backbone/model_efficientnet.pth`
- Label encoders to: `backend/models/encodings/label_encoders.json`
Option 1 â€” Train from scratch:


***Option 2*** â€” Download pretrained:

ğŸ‘‰ [Download pretrained model (.pth) + label encoders](#  Fashion Product Classifier

A full-stack Machine Learning web application that predicts multiple attributes of fashion products from images using deep learning. This project was developed as part of a coding assignment for Codemonkâ€™s Machine Learning Internship.

---

## ğŸš€ Project Overview

Given an input image of a fashion product, this system predicts the following four attributes:

-  **Color**
-  **Product Type**
-  **Season of Use**
-  **Target Gender**

It uses multi-task deep learning to handle all four tasks in a single model and provides visual heatmaps for interpretability.

---
## ğŸš§ Pending Improvements

While the core pipeline is completeâ€”from preprocessing to prediction and visualizationâ€”several improvements are planned to enhance functionality, performance, and user experience:

- **ğŸ§  Additional Architectures:**
    - [ ] Integrate Vision Transformer (ViT) with 4-head classification.
  - [ ] Experiment with Mixture-of-Experts (MoE) heads for advanced ensembling.

- **ğŸ“Š Evaluation & Metrics:**
  - [ ] Add confusion matrices and classification reports per task.
- **ğŸ”§ Backend Enhancements:**
  - [ ] Add batch image support for predictions.
- **ğŸ’¡ Explainability:**
  - [ ] Improve Grad-CAM precision by using hooks on intermediate layers.
---

## ğŸ“š Table of Contents

## ğŸ“š Table of Contents

- [Project Overview](#project-overview)
- [Project Structure](#project-structure)
- [How to Run This Project](#how-to-run-this-project)
- [ğŸ¥ Demo](#-demo)
- [ğŸ§ª Pending Improvements](#-pending-improvements)
- [ğŸ§  Model Checkpoints](#-model-checkpoints)
- [ğŸ‘¤ Author](#-author)



## ğŸ§± Project Architecture

### Multi-Head Learning Model 

- **Backbone**: `EfficientNetV2-S` (pretrained on ImageNet)
- **Shared Encoder**: Extracts rich image features
- **Four Classification Heads**:
  - Color
  - Product Type
  - Season
  - Gender
- **Regularization**: Dropout applied to each head
- **Loss**: Independent `CrossEntropyLoss` for each task
- **Training Framework**: PyTorch

> ğŸ† This model design is efficient, generalizes well, and leverages shared representations to boost performance across tasks.

---
## Frontend

- **Framework**: [Streamlit](https://streamlit.io)
- **Features**:
  - Upload fashion product image
  - Displays predicted color, type, season, and gender
  - Shows visual heatmap of model attention

---

## Backend

- **Framework**: [FastAPI](https://fastapi.tiangolo.com/)
- **APIs**:
  - `POST /predict`: Takes an image, returns predictions + heatmap path
- **Model Inference**:
  - Loads trained EfficientNet multi-task model
  - Decodes predicted labels using saved `label_encoders.json`

---
## Explainability

- **Grad-CAM** heatmaps are generated for each input image using the shared EfficientNet backbone.
- The heatmaps highlight which regions of the image were most influential in the predictions.

---



## Project Structure
```sh
fashion-product-classifier/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI app entrypoint
â”‚ â”œâ”€â”€ routes/ # API endpoints
â”‚ â”œâ”€â”€ services/ # Prediction logic, heatmap gen
â”‚ â”œâ”€â”€ utils/ # Preprocessing helpers
â”‚ â”œâ”€â”€ models/ # Model architecture + checkpoints + encodings 
â”‚ â”‚ â””â”€â”€ effi_net_backbone/
â”‚ â”‚ â”œâ”€â”€ model_efficientnet.pth
â”‚ â”‚ â””â”€â”€ label_encoders.json
â”‚ â””â”€â”€ static/ # Heatmaps served here
â”‚ â””â”€â”€ heatmaps/
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ app.py # Streamlit frontend UI
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ fashion-product-images-dataset/
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ cleaned_styles.csv
â”‚ â””â”€â”€ distribution_plots/
â”‚
â”œâ”€â”€ data_preprocessing/
â”‚ â”œâ”€â”€ clean_data.py # CSV cleaning
â”‚ â””â”€â”€ class_distribution.py # Plots label distributions
â”‚
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ efficientnet_training.py # EfficientNet training script
â”‚ â””â”€â”€ vit_training.py # (NOT IMPLEMENTED YET) ViT training script
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ› ï¸ How to Run This Project

###  Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

> Ensure you have:
> - Python 3.8+
> - PyTorch with GPU support (optional but recommended)

---

###  Step 2: Preprocess the Dataset

```bash
python data_preprocessing/clean_data.py
python data_preprocessing/class_distribution.py
```

---

###  Step 3: Train the Model
***Option 1*** â€” Train from scratch:
```bash
python training/efficientnet_training.py
```
This will save:
- Model weights to: `backend/models/effi_net_backbone/model_efficientnet.pth`
- Label encoders to: `backend/models/encodings/label_encoders.json`
Option 1 â€” Train from scratch:


***Option 2*** â€” Download pretrained:

ğŸ‘‰ [Download pretrained model (.pth) + label encoders](https://drive.google.com/drive/folders/YOUR_FOLDER_ID)

Then place them inside:

```
backend/models/
â”œâ”€â”€ effi_net_backbone/model_efficientnet.pth
â””â”€â”€ encodings/label_encoders.json
```
---

###  Step 4: Run Backend API (FastAPI)

```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8080 --reload
```

> The API will be live at: [http://127.0.0.1:8080](http://127.0.0.1:8080)

---

###  Step 5: Run Frontend (Streamlit)

```bash
streamlit run frontend/app.py
```

> The UI will open in your browser â†’ Upload an image â†’ Get predictions + visual heatmap.

## Demo

[Demo](assets/demo.gif)

> Predictions are returned with corresponding Grad-CAM heatmap.
---
## ğŸ“¦ Model Checkpoints

You can download the pre-trained model and label encoders here:

ğŸ‘‰ [EfficientNetV2 Backbone Checkpoint (.pth) + Label Encoders](https://drive.google.com/drive/folders/1xQVRHiBioyCYDghrJk-5HKf7c6vZt_Z9?usp=drive_link)

> Place the downloaded files in:
> ```
> backend/models/
> â”œâ”€â”€ effi_net_backbone/model_efficientnet.pth
> â””â”€â”€ encodings/label_encoders.json
> ```

---
## ğŸ‘¨â€ğŸ’» Author

**Mohammad Hamza Bhat**  
ML Intern Candidate @ Codemonk  
ğŸ“§ Email: [hamzabhat88@gmail.com](mailto:hamzabhat88@gmail.com)   
Phone: +91 9797860227
)

Then place them inside:

```
backend/models/
â”œâ”€â”€ effi_net_backbone/model_efficientnet.pth
â””â”€â”€ encodings/label_encoders.json
```
---

###  Step 4: Run Backend API (FastAPI)

```bash
cd backend
uvicorn main:app --reload
```

> The API will be live at: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

###  Step 5: Run Frontend (Streamlit)

```bash
cd frontend
streamlit run app.py
```

> The UI will open in your browser â†’ Upload an image â†’ Get predictions + visual heatmap.

## Example Output

|  Input Image |  Predictions |  Heatmap |
|----------------|----------------|------------|
| ![product](https://via.placeholder.com/150x150?text=Image) |  **Color**: Blue<br> **Type**: T-shirts<br> **Season**: Summer<br> **Gender**: Unisex | ![heatmap](https://via.placeholder.com/150x150?text=GradCAM) |

> Predictions are returned with corresponding Grad-CAM heatmap.
---
## ğŸ“¦ Model Checkpoints

You can download the pre-trained model and label encoders here:

ğŸ‘‰ [EfficientNetV2 Backbone Checkpoint (.pth) + Label Encoders](https://drive.google.com/drive/folders/1xQVRHiBioyCYDghrJk-5HKf7c6vZt_Z9?usp=drive_link)

> Place the downloaded files in:
> ```
> backend/models/
> â”œâ”€â”€ effi_net_backbone/model_efficientnet.pth
> â””â”€â”€ encodings/label_encoders.json
> ```

---
## ğŸ‘¨â€ğŸ’» Author

**Mohammad Hamza Bhat**  
ML Intern Candidate @ Codemonk  
ğŸ“§ Email: [hamzabhat88@gmail.com](mailto:hamzabhat88@gmail.com)   
Phone: +91 9797860227
