{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eae2fbc-d9f0-4cfd-8251-bddc99acde06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cf943-0d36-4db1-b0f1-756c795a0843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5fb58d-9124-4bca-88a3-40ce8192c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskEfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A multi-task learning model using a pre-trained EfficientNetV2-S as a backbone.\n",
    "    It has four separate classification heads to predict color, type, season, and gender.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_colors, num_types, num_seasons, num_genders):\n",
    "        super().__init__()\n",
    "        # Load pre-trained backbone with the latest recommended weights\n",
    "        self.backbone = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "        # Freeze all parameters in the backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get the number of input features for the classifier\n",
    "        n_features = self.backbone.classifier[1].in_features\n",
    "        # Replace the classifier with an Identity layer to get the features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # Define separate heads for each task, with Dropout for regularization\n",
    "        self.color_head = nn.Sequential(nn.Dropout(p=0.4), nn.Linear(n_features, num_colors))\n",
    "        self.type_head = nn.Sequential(nn.Dropout(p=0.4), nn.Linear(n_features, num_types))\n",
    "        self.season_head = nn.Sequential(nn.Dropout(p=0.4), nn.Linear(n_features, num_seasons))\n",
    "        self.gender_head = nn.Sequential(nn.Dropout(p=0.4), nn.Linear(n_features, num_genders))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the backbone to get shared features\n",
    "        features = self.backbone(x)\n",
    "        # Pass features through each head to get task-specific outputs\n",
    "        return {\n",
    "            'color': self.color_head(features),\n",
    "            'product_type': self.type_head(features),\n",
    "            'season': self.season_head(features),\n",
    "            'gender': self.gender_head(features)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07930a40-47c3-4361-997d-4079d2a5f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    \"\"\"Defines the augmentation pipeline for the training set.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(p=0.7, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        A.CoarseDropout(max_holes=1, max_height=64, max_width=64, p=0.5),\n",
    "\n",
    "\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_val_augs():\n",
    "    \"\"\"Defines the augmentation pipeline for the validation/test set.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height=224, width=224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f19248-6adf-4feb-a510-659fd22b79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for loading fashion product images and labels.\"\"\"\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.data = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get the row from the dataframe\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{row['id']}.jpg\")\n",
    "        \n",
    "        # Open image and convert to RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformations if they exist\n",
    "        if self.transform:\n",
    "            image_np = np.array(image)\n",
    "            augmented = self.transform(image=image_np)\n",
    "            image = augmented['image']\n",
    "\n",
    "        # Get the labels\n",
    "        labels = {\n",
    "            'color': torch.tensor(row['color_label'], dtype=torch.long),\n",
    "            'product_type': torch.tensor(row['type_label'], dtype=torch.long),\n",
    "            'season': torch.tensor(row['season_label'], dtype=torch.long),\n",
    "            'gender': torch.tensor(row['gender_label'], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299bcec-ce58-4b21-9321-d2cd8a28e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ Label encoders saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\label_encoders.json\n",
      "✅ Train shape: (37385, 14), Val shape: (6598, 14)\n",
      "Training on 37385 samples, validating on 6598 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_35012\\496865969.py:7: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=64, max_width=64, p=0.5),\n",
      "C:\\Users\\hamza\\anaconda3\\envs\\codemonk_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [59:41<00:00,  6.12s/it, loss=5.77]\n",
      "Epoch 1/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [09:58<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10 | Avg Train Loss: 5.3480 | Avg Val Loss: 4.4483\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [55:49<00:00,  5.73s/it, loss=5.76]\n",
      "Epoch 2/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [08:15<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10 | Avg Train Loss: 4.4965 | Avg Val Loss: 4.1178\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [53:59<00:00,  5.54s/it, loss=4.59]\n",
      "Epoch 3/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [09:14<00:00,  5.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10 | Avg Train Loss: 4.3465 | Avg Val Loss: 3.9645\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [49:33<00:00,  5.08s/it, loss=4.45]\n",
      "Epoch 4/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [07:55<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10 | Avg Train Loss: 4.2874 | Avg Val Loss: 3.8291\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [46:22<00:00,  4.76s/it, loss=4.11]\n",
      "Epoch 5/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [07:56<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10 | Avg Train Loss: 4.2308 | Avg Val Loss: 3.7997\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [46:01<00:00,  4.72s/it, loss=5.46]\n",
      "Epoch 6/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [07:50<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10 | Avg Train Loss: 4.2269 | Avg Val Loss: 3.7832\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [46:17<00:00,  4.75s/it, loss=6.19]\n",
      "Epoch 7/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [07:54<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10 | Avg Train Loss: 4.1945 | Avg Val Loss: 3.7490\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [49:07<00:00,  5.04s/it, loss=6.51]\n",
      "Epoch 8/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [08:29<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10 | Avg Train Loss: 4.1820 | Avg Val Loss: 3.7370\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Training]: 100%|██████████████████████████████████████████████| 585/585 [49:18<00:00,  5.06s/it, loss=4.25]\n",
      "Epoch 9/10 [Validation]: 100%|███████████████████████████████████████████████████████| 104/104 [07:54<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10 | Avg Train Loss: 4.1619 | Avg Val Loss: 3.6951\n",
      "Validation loss improved. Model saved to D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\effi_net_backbone\\model_efficientnet.pth\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Training]:  16%|███████▌                                      | 96/585 [07:44<44:59,  5.52s/it, loss=4.08]"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuration ---\n",
    "csv_path = r'D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\data\\processed\\cleaned-styles.csv'\n",
    "img_dir = r'D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\data\\raw\\fashion-product-images-dataset\\images'\n",
    "model_save_path = r'D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\checkpoints\\model_efficientnet.pth'\n",
    "encoder_save_path = r'D:\\CODING\\Machine Learning\\PROJECTS\\fashion-product-classifier\\backend\\models\\encodings\\label_encoders.json'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "os.makedirs('./backend/models/', exist_ok=True)\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Create and save label encoders\n",
    "encoders = {}\n",
    "label_cols = ['baseColour', 'articleType', 'season', 'gender']\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Create new column with encoded labels\n",
    "    df[f'{col.replace(\"baseColour\", \"color\").replace(\"articleType\", \"type\")}_label'] = le.fit_transform(df[col])\n",
    "    # Store encoder classes for decoding later\n",
    "    encoders[col] = {str(i): c for i, c in enumerate(le.classes_)}\n",
    "\n",
    "with open(encoder_save_path, 'w') as f:\n",
    "    json.dump(encoders, f, indent=4)\n",
    "print(f\" Label encoders saved to {encoder_save_path}\")\n",
    "\n",
    "num_classes = {\n",
    "    'colors': len(encoders['baseColour']),\n",
    "    'types': len(encoders['articleType']),\n",
    "    'seasons': len(encoders['season']),\n",
    "    'genders': len(encoders['gender'])\n",
    "}\n",
    "\n",
    "# --- 3. Train/Validation Split ---\n",
    "# Stratify by 'articleType' to ensure balanced classes in both splits\n",
    "# Remove rare articleType classes that occur only once\n",
    "valid_article_types = df['articleType'].value_counts()\n",
    "df = df[df['articleType'].isin(valid_article_types[valid_article_types > 1].index)]\n",
    "\n",
    "# Stratified train/val split on cleaned data\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df['articleType']\n",
    ")\n",
    "\n",
    "print(f\"✅ Train shape: {train_df.shape}, Val shape: {val_df.shape}\")\n",
    "train_dataset = FashionDataset(train_df, img_dir, transform=get_train_augs())\n",
    "val_dataset = FashionDataset(val_df, img_dir, transform=get_val_augs())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples.\")\n",
    "\n",
    "# --- 4. Initialize Model, Loss, and Optimizer ---\n",
    "model = MultiTaskEfficientNet(\n",
    "    num_classes['colors'], num_classes['types'], num_classes['seasons'], num_classes['genders']\n",
    ").to(device)\n",
    "\n",
    "# Using simple unweighted loss here, but you can add class weights if needed\n",
    "criterion = {\n",
    "    'color': nn.CrossEntropyLoss(),\n",
    "    'product_type': nn.CrossEntropyLoss(),\n",
    "    'season': nn.CrossEntropyLoss(),\n",
    "    'gender': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "# --- 5. Training & Validation Loop ---\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 10 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\")\n",
    "    for images, targets in train_loop:\n",
    "        images = images.to(device)\n",
    "        targets = {k: v.to(device) for k, v in targets.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = sum(criterion[task](outputs[task], targets[task]) for task in outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loop:\n",
    "            images = images.to(device)\n",
    "            targets = {k: v.to(device) for k, v in targets.items()}\n",
    "            outputs = model(images)\n",
    "            loss = sum(criterion[task](outputs[task], targets[task]) for task in outputs)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs} | Avg Train Loss: {avg_train_loss:.4f} | Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Save the best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Validation loss improved. Model saved to {model_save_path}\")\n",
    "\n",
    "print(\" Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f81c77-4f21-4319-b09e-c2eafb2d1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f29fc4-9289-49d6-a8be-4bd55d1b0968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adeb691-89fa-4f96-a085-c1fa2e567074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Enabled Env",
   "language": "python",
   "name": "codemonk_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
